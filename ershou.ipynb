{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "import requests\n",
    "from scrapy.selector import Selector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from multiprocessing import Pool\n",
    "from fake_useragent import UserAgent\n",
    "from sqlalchemy import create_engine\n",
    "from concurrent.futures import ThreadPoolExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://root:123456@localhost:3306/fang\", encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pagelist():\n",
    "    pagelist=[]\n",
    "    pagelist.append([0,40])\n",
    "    for i in range(40,60,20):\n",
    "        pagelist.append([i,i+20])\n",
    "    for i in range(60,200,10):\n",
    "        pagelist.append([i,i+10])\n",
    "    for i in range(200,250,25):\n",
    "        pagelist.append([i,i+25])\n",
    "    for i in range(250,600,50):\n",
    "        pagelist.append([i,i+50])\n",
    "    for i in range(600,3000,400):\n",
    "        pagelist.append([i,i+400])\n",
    "    for i in range(3000,5000,2000):\n",
    "        pagelist.append([i,i+2000])\n",
    "    # print(pagelist)\n",
    "    return pagelist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#全局变量\n",
    "# headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'}\n",
    "ua=UserAgent()\n",
    "headers = { 'User-Agent':ua.random}\n",
    "\n",
    "# districts=['jiangbei','yubei','shapingba','jiulongpo','nanan','dadukou','banan','beibei']\n",
    "districts_test=['beibei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先分区域，按价格分页面进行查询，确认不存在超出3000套房源的页面\n",
    "def test_if_more_than_3000(districts,pagelist):\n",
    "    for district in districts:\n",
    "        for page in pagelist:\n",
    "            bp=page[0]\n",
    "            ep=page[1]\n",
    "            url=f'https://cq.lianjia.com/ershoufang/{district}/bp{bp}ep{ep}/'\n",
    "            resp1=requests.get(url,headers =headers)\n",
    "            find_all_houses=int(Selector(resp1).css('h2.total.fl span::text').extract_first())\n",
    "            if find_all_houses ==0:\n",
    "                continue\n",
    "            if find_all_houses>3000:\n",
    "                print(f'{district}--{bp}--{ep}--------超出3000套')\n",
    "        print(district+f'查找完毕!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pd_to_sql(dataframe,table_name,engine,if_exists_method='append',index_true_or_false=False):\n",
    "    dataframe.to_sql(f'{table_name}', con=engine, if_exists=f'{if_exists_method}', index=index_true_or_false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到页面中房源总数，返回应该划分的页面数\n",
    "def get_total_fang_nums(headers,bp,ep,district,num_per_page):\n",
    "    url=f'https://cq.lianjia.com/ershoufang/{district}/bp{bp}ep{ep}/'\n",
    "    resp=requests.get(url,headers = headers)\n",
    "    #首先查询共找到的房源套数\n",
    "    find_houses_nums=int(Selector(resp).css('h2.total.fl span::text').extract_first())\n",
    "    if find_houses_nums ==0:\n",
    "        return 0\n",
    "    #每页为30条数据\n",
    "    elif find_houses_nums%num_per_page !=0:\n",
    "        return find_houses_nums//num_per_page+1\n",
    "    else:\n",
    "        return find_houses_nums//num_per_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_district_pg_bp_ep_(district,pg,bp,ep,headers):\n",
    "    url=f'https://cq.lianjia.com/ershoufang/{district}/pg{pg}bp{bp}ep{ep}/'\n",
    "    response=requests.get(url,headers = headers)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_response(response):\n",
    "    if response.status_code !=200:\n",
    "        print('ERROR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataframe_ready(sel):\n",
    "    #准备空dataframe，用于每页的数据存储\n",
    "    houses_dataframe=pd.DataFrame(columns=('community_name','page_link','location',\n",
    "                                 'total_price','unit_price','room_nums',\n",
    "                                 'built_area','built_time','board_time','last_deal','loan_or_not','house_type'))\n",
    "    for item in sel:\n",
    "        house_info={}\n",
    "        try:\n",
    "            community_name,location=item.css('div.positionInfo a::text').extract()\n",
    "            house_info['community_name']=community_name\n",
    "\n",
    "            page_link=item.css('div.title a::attr(href)').extract_first()\n",
    "            house_info['page_link']=page_link\n",
    "\n",
    "            house_info['location']=location\n",
    "\n",
    "            total_price=int(float(item.css('div.totalPrice span::text').extract_first()))\n",
    "            house_info['total_price']=total_price\n",
    "            unit_price=item.css('div.unitPrice span::text').extract_first()\n",
    "            unit_price=int(float(re.findall('单价(\\d+)元',unit_price)[0]))\n",
    "            house_info['unit_price']=unit_price\n",
    "\n",
    "            house_informations=item.css('div.houseInfo::text').extract_first().split('|')\n",
    "            room_nums=house_informations[0].strip()\n",
    "\n",
    "            house_info['room_nums']=room_nums\n",
    "            built_area=int(re.match('(\\d+)(\\\\.\\d+)?平米',house_informations[1].strip()).group(1))\n",
    "            house_info['built_area']=built_area\n",
    "\n",
    "            built_time=house_informations[5].strip()\n",
    "            built_time=None if '年建' not in built_time else (re.match('(\\d+)年建',built_time).group(1))\n",
    "            house_info['built_time']=built_time\n",
    "\n",
    "            resp2=requests.get(page_link,headers = headers)\n",
    "            response_in_link=Selector(response=resp2)\n",
    "\n",
    "            board_time=response_in_link.css('span:contains(\"挂牌时间\")+span::text').extract_first()\n",
    "            house_info['board_time']=board_time\n",
    "            last_deal=response_in_link.css('span:contains(\"上次交易\")+span::text').extract_first()\n",
    "            last_deal=None if last_deal ==\"暂无数据\" else last_deal\n",
    "            house_info['last_deal']=last_deal\n",
    "\n",
    "            loan_or_not=response_in_link.css('span:contains(\"抵押信息\")+span::text').extract_first().strip()\n",
    "\n",
    "            loan_or_not=None if loan_or_not ==\"暂无数据\" else(re.match('(\\w)抵押.*',loan_or_not).group(1))\n",
    "            house_info['loan_or_not']=loan_or_not\n",
    "\n",
    "            house_type=response_in_link.css('span:contains(\"房屋用途\")+span::text').extract_first().strip()\n",
    "            house_info['house_type']=house_type\n",
    "        except:\n",
    "            print(f'{page_link}   获取失败！')\n",
    "            return None\n",
    "\n",
    "        houses_dataframe=houses_dataframe.append(house_info,ignore_index=True)\n",
    "        return houses_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main(pagelist):\n",
    "    for district in districts_test:\n",
    "        for page in pagelist:\n",
    "            bp=page[0]\n",
    "            ep=page[1]\n",
    "            for pg in range(1,get_total_fang_nums(headers,bp,ep,district,30)+1):\n",
    "                response=get_response_from_district_pg_bp_ep_(district,pg,bp,ep,headers)\n",
    "                sel=Selector(response).css('li.clear.LOGVIEWDATA')\n",
    "                dataframe=get_dataframe_ready(sel)\n",
    "                if dataframe is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    try:\n",
    "                        pd_to_sql(dataframe,district,engine,'append',False)\n",
    "                        print(f'{district}-pg{pg}-bp{bp}--ep{ep}数据已写入table{district}')\n",
    "                    except:\n",
    "                        print(f'{district}-pg{pg}-bp{bp}--ep{ep}-------------数据写入失败！！！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    with ThreadPoolExecutor(max_workers=6) as executor:\n",
    "        executor.map(main, test_pagelist())\n",
    "        \n",
    "#     pool = Pool(4)\n",
    "#     pool.map(main,test_pagelist())\n",
    "#     pool.close()\n",
    "#     pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tablebeibei已清空还原\n"
     ]
    }
   ],
   "source": [
    "#清空数据库数据专用\n",
    "def roll_back_table(table_name):\n",
    "    houses=pd.DataFrame(columns=('community_name','page_link','location',\n",
    "                                             'total_price','unit_price','room_nums',\n",
    "                                             'built_area','built_time','board_time','last_deal','loan_or_not','house_type'))\n",
    "    houses.to_sql(f'{table_name}', con=engine, if_exists='replace', index=False)\n",
    "    print(f'table{table_name}已清空还原')\n",
    "\n",
    "roll_back_table('beibei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
